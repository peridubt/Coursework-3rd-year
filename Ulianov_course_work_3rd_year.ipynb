{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Импорт библиотек"
   ],
   "metadata": {
    "id": "8ApPJ6x5wopM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install osmnx"
   ],
   "metadata": {
    "id": "_mdpqm6e0VuK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a305dd1b-9021-4a92-cbca-83f13decc5e2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting osmnx\n",
      "  Downloading osmnx-2.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: geopandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from osmnx) (1.0.1)\n",
      "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.11/dist-packages (from osmnx) (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.32.3)\n",
      "Requirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.0.7)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (0.10.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (24.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (3.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n",
      "Downloading osmnx-2.0.1-py3-none-any.whl (99 kB)\n",
      "\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/99.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.6/99.6 kB\u001B[0m \u001B[31m6.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: osmnx\n",
      "Successfully installed osmnx-2.0.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install haversine"
   ],
   "metadata": {
    "id": "EjCzkPrX0XzR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6f1d1c37-6d1c-4e62-c10c-de433f5dd0ed"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting haversine\n",
      "  Downloading haversine-2.9.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading haversine-2.9.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: haversine\n",
      "Successfully installed haversine-2.9.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_97UifVTjeQl",
    "ExecuteTime": {
     "end_time": "2025-03-25T18:34:18.547579Z",
     "start_time": "2025-03-25T18:34:18.540344Z"
    }
   },
   "source": [
    "import torch  # pytorch\n",
    "import json  # чтение json файла\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim  # регуляризация модели\n",
    "from torch.nn.utils.rnn import pad_sequence  # выраванивание последовательностей\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split  # разделение выборки на test/train\n",
    "from sklearn.preprocessing import MinMaxScaler  # нормализация данных\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import osmnx as ox  # библиотека для работы с OSM\n",
    "import networkx as nx  # для работы с графами местностей\n",
    "from geopy.distance import geodesic as gd\n",
    "\n",
    "from haversine import haversine, Unit  # вычисление расстояний между точками кординат\n",
    "from scipy.interpolate import interp1d  # интерполяция маршрутов\n",
    "\n",
    "import os\n",
    "import folium  # для построения html-запросов к leafnet и вывода маршрутов\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error  # метрики для модели"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Рекуррентные нейронные сети"
   ],
   "metadata": {
    "id": "isXu_940_Hl9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Класс модели LSTM"
   ],
   "metadata": {
    "id": "iqxMaMolz8-F"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Слои LSTM являются двунаправленными, т.е. они могут работать как с данными из прошлого, так и с предсказанными, отсюда для линейного слоя размер скрытого слоя увеличен в 2 раза."
   ],
   "metadata": {
    "id": "7JYK6an-wqJc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # проходим через LSTM\n",
    "        out, _ = self.lstm(x)\n",
    "        # проходим через линейный слой\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "id": "0d-8cn4djhzk",
    "ExecuteTime": {
     "end_time": "2025-03-25T18:34:33.613081Z",
     "start_time": "2025-03-25T18:34:33.586682Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Загрузка обученной модели (опционально)"
   ],
   "metadata": {
    "id": "uOdXM18J3Ijx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Можно пропустить этап с обучением и сразу загрузить обученную модель (lstm_model.pth) с установившимися параметрами и перейти к шагу с [примером](https://colab.research.google.com/drive/1WcNZ3E7X6JpAAkMWuinQIQ_PZWZPP2h1#scrollTo=El_K5tZg1AuN&line=1&uniqifier=1)."
   ],
   "metadata": {
    "id": "XrM9AMgQ3O9R"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!gdown 16Hbvud9yHTT22XZ4WLZ0g4JfWkjsikx1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-KX19Zy53Jhl",
    "outputId": "7df9ae0e-c0fa-4edd-83ff-c46c33e4de59"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=16Hbvud9yHTT22XZ4WLZ0g4JfWkjsikx1\n",
      "To: /content/lstm_model.pth\n",
      "\r  0% 0.00/546k [00:00<?, ?B/s]\r100% 546k/546k [00:00<00:00, 13.9MB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Параметры модели"
   ],
   "metadata": {
    "id": "xcBUr1VV0D8D"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для модели были выбраны следующие параметры:\n",
    "- входной и выходной размеры = 2, т.к. последовательность имеет размерность N x 2, т.е. ширина и долгота\n",
    "- размер скрытого слоя LSTM = 64\n",
    "- число слоёв LSTM = 2\n",
    "- размер одного батча (отрезка) при обучении модели = 128\n",
    "\n",
    "Другие характеристики:\n",
    "- В качестве предобработки данные были нормализованы в интервале от -1 до 1 для более эффективной работы функции активации в виде гиперболического тангенса, содержащейся в слое LSTM.\n",
    "- В качестве функции ошибки была выбрана среднеквадратическая ошибка (MSE).\n",
    "- Для регуляризации был выбран оптимизатор AdamW."
   ],
   "metadata": {
    "id": "-y19UyUAw1q_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sc = MinMaxScaler(feature_range=(-1, 1))  # для нормализации данных от -1 до 1\n",
    "\n",
    "# Параметры модели\n",
    "input_size = 2\n",
    "hidden_size = 64\n",
    "output_size = 2\n",
    "num_layers = 2\n",
    "batch_size = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# создаём модель\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "# функция потерь и оптимизатор\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "loss_fn = nn.CTCLoss()"
   ],
   "metadata": {
    "id": "J00_HHpNjnSs",
    "ExecuteTime": {
     "end_time": "2025-03-25T18:34:40.935229Z",
     "start_time": "2025-03-25T18:34:37.234510Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Загрузка и предобработка данных"
   ],
   "metadata": {
    "id": "x7Cnhx5vzQ_J"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Подгрузка выборки в виде последовательностей координат в количестве 10000 штук (routes.json)"
   ],
   "metadata": {
    "id": "bKdw4s2U0mth"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!gdown 1VYI0Mi5XTASGDon33RNMjdMlkCKynA0k"
   ],
   "metadata": {
    "id": "bu3oCSUZ0mYX",
    "ExecuteTime": {
     "end_time": "2025-03-25T18:34:55.628543Z",
     "start_time": "2025-03-25T18:34:55.572750Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"gdown\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузка данных выборки из файла"
   ],
   "metadata": {
    "id": "pRLSncLRwteF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Загрузка маршрутов\n",
    "routes_path = \"training data\\\\routes.json\"\n",
    "with (open(routes_path, 'r', encoding='utf-8')) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "X, y = data['X'], data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42)"
   ],
   "metadata": {
    "id": "ryDnZ7uZjlX1",
    "ExecuteTime": {
     "end_time": "2025-03-25T23:09:48.305634Z",
     "start_time": "2025-03-25T23:09:43.222747Z"
    }
   },
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "Происходит выравнивание последовательностей в соответствии с самой длинной последовательностью и их преобразование в тензоры, далее следует нормализация в отрезок [-1; 1]. После выравнивания лишние элементы будут иметь координаты (0, 0). Затем данные загружаются в dataset и dataloader\n",
    "\n",
    "(*стоит дополнительно заняться эмбеддингом лишних элементов, чтобы модель их могла не учитывать*)"
   ],
   "metadata": {
    "id": "EPgo3PUZyE43"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = [torch.tensor(sc.fit_transform(seq), dtype=torch.float32) for seq in X_train]\n",
    "y_train = [torch.tensor(sc.fit_transform(seq), dtype=torch.float32) for seq in y_train]\n",
    "X_train_pad = pad_sequence(X_train, batch_first=True)\n",
    "y_train_pad = pad_sequence(y_train, batch_first=True)\n",
    "\n",
    "X_test = [torch.tensor(sc.fit_transform(seq), dtype=torch.float32) for seq in X_test]\n",
    "y_test = [torch.tensor(sc.fit_transform(seq), dtype=torch.float32) for seq in y_test]\n",
    "X_test_pad = pad_sequence(X_test, batch_first=True)\n",
    "y_test_pad = pad_sequence(y_test, batch_first=True)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_pad, y_train_pad)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_pad, y_test_pad)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "id": "-Bk9CSmBjtkY",
    "ExecuteTime": {
     "end_time": "2025-03-25T23:10:01.589858Z",
     "start_time": "2025-03-25T23:09:49.862016Z"
    }
   },
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Обучение модели"
   ],
   "metadata": {
    "id": "-nvec7ZpzWFK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "На обучение выделено 10 эпох."
   ],
   "metadata": {
    "id": "yimv0P4eykzy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 10  # Количество эпох при обучении\n",
    "train_hist = []\n",
    "test_hist = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:  # выборка разделяется на части (батчи)\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        predictions = model(batch_X)\n",
    "        loss = loss_fn(predictions, batch_y)  # для каждого батча считается функция потерь\n",
    "\n",
    "        # обратное распространение ошибки\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    train_hist.append(average_loss)\n",
    "\n",
    "    # расчёты для тестовых бачтей\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0.0\n",
    "\n",
    "        for batch_X_test, batch_y_test in test_loader:\n",
    "            batch_X_test, batch_y_test = batch_X_test.to(device), batch_y_test.to(device)\n",
    "            predictions_test = model(batch_X_test)\n",
    "            test_loss = loss_fn(predictions_test, batch_y_test)\n",
    "\n",
    "            total_test_loss += test_loss.item()\n",
    "\n",
    "        average_test_loss = total_test_loss / len(test_loader)\n",
    "        test_hist.append(average_test_loss)\n",
    "\n",
    "    print(\n",
    "        f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}, Test Loss: {average_test_loss:.4f}')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbsdzTfjjxDq",
    "outputId": "ce7cb97e-0f4b-423b-9620-f6d0417d2b2f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [1/10] - Training Loss: 0.0203, Test Loss: 0.0040\n",
      "Epoch [2/10] - Training Loss: 0.0040, Test Loss: 0.0037\n",
      "Epoch [3/10] - Training Loss: 0.0037, Test Loss: 0.0036\n",
      "Epoch [4/10] - Training Loss: 0.0036, Test Loss: 0.0035\n",
      "Epoch [5/10] - Training Loss: 0.0035, Test Loss: 0.0034\n",
      "Epoch [6/10] - Training Loss: 0.0035, Test Loss: 0.0034\n",
      "Epoch [7/10] - Training Loss: 0.0033, Test Loss: 0.0033\n",
      "Epoch [8/10] - Training Loss: 0.0032, Test Loss: 0.0032\n",
      "Epoch [9/10] - Training Loss: 0.0030, Test Loss: 0.0030\n",
      "Epoch [10/10] - Training Loss: 0.0029, Test Loss: 0.0028\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Параметры модели можно сохранить в отдельном файле"
   ],
   "metadata": {
    "id": "-U3JtW98y_T4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model, './lstm_model.pth')"
   ],
   "metadata": {
    "id": "BOQeq2XOl1Rx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Пример использования"
   ],
   "metadata": {
    "id": "El_K5tZg1AuN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузка файла конфигурации (config.json)."
   ],
   "metadata": {
    "id": "H4qW8lvnzCsf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!gdown 1uTIYTjQHau5R0kOhQG3lspQ-EA16SHxp"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRIJEdPpwEDS",
    "outputId": "b220dd07-e1b2-4636-a042-31e609d4a904"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1uTIYTjQHau5R0kOhQG3lspQ-EA16SHxp\n",
      "To: /content/config.json\n",
      "\r  0% 0.00/163 [00:00<?, ?B/s]\r100% 163/163 [00:00<00:00, 397kB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Класс генератора маршрутов"
   ],
   "metadata": {
    "id": "neI78t0Y1Fs9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class RouteGenerator:\n",
    "    def __init__(self, config_path: str = \"config.json\", **kwargs):\n",
    "        \"\"\"Конструктор класса, которому в именованных аргументах передаётся\n",
    "        либо название местности, либо точные координаты местности.\n",
    "        Если было передано название, то происходит обращение к базе данных OSM,\n",
    "        где потом извлекаются точные координаты. На основе координат строится граф дорог.\n",
    "\n",
    "\n",
    "        Args:\n",
    "            config_path (str, optional): Путь к файлу конфигурации. По умолчанию стоит \"config.json\".\n",
    "\n",
    "        Raises:\n",
    "            Exception: Не были переданы ни название местности, ни его координаты.\n",
    "        \"\"\"\n",
    "\n",
    "        self.__load_config(config_path)\n",
    "        self.data = {'X': [], 'y': []}\n",
    "\n",
    "        if \"place_name\" in kwargs.keys():\n",
    "            self.__place_bbox = list(\n",
    "                ox.geocode_to_gdf(kwargs[\"place_name\"]).geometry.total_bounds\n",
    "            )\n",
    "\n",
    "        elif \"place_bbox\" in kwargs.keys():\n",
    "            self.__place_bbox = kwargs[\"place_bbox\"]\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Укажите название места согласно базе данных OSM либо координаты местности.\"\n",
    "            )\n",
    "\n",
    "        self.graph = ox.graph_from_bbox(self.__place_bbox, network_type=\"drive\")  # Граф дорог местности\n",
    "\n",
    "    def __load_config(self, file_path: str) -> None:\n",
    "        \"\"\"Загрузка данных о константах через файл конфигурации.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Путь к файлу конфигурации.\n",
    "        \"\"\"\n",
    "\n",
    "        with open(file_path, \"r\") as file:\n",
    "            config = json.load(file)\n",
    "            self.__data_amount = config[\"data_amount\"]  # Размер генерируемой выборки\n",
    "            self.__min_segment = config[\n",
    "                \"min_segment\"\n",
    "            ]  # Минимальное значение отрезка для создания отклонения\n",
    "            self.__max_segment = config[\n",
    "                \"max_segment\"\n",
    "            ]  # Максимальное значение отрезка для создания отклонения\n",
    "            self.__min_offset = config[\"min_offset\"]  # Минимальное отклонение\n",
    "            self.__max_offset = config[\"max_offset\"]  # Максимальное отклонение\n",
    "            self.__max_route_len = config[\"max_route_len\"]\n",
    "            self.__min_route_len = config[\"min_route_len\"]\n",
    "\n",
    "    def save_false_route(self, main_route: list) -> tuple:\n",
    "        \"\"\"Генерация одного искажённого маршрута на основе исходного.\n",
    "\n",
    "        Args:\n",
    "            main_route: (list): Исходный маршрут.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[nx.Graph, list]: Кортеж, внутри которого помещён изменённый граф и полученный маршрут.\n",
    "        \"\"\"\n",
    "\n",
    "        path = main_route\n",
    "        G = self.graph.copy()\n",
    "        new_nodes = [path[0]]\n",
    "\n",
    "        for i in range(len(path) - 1):\n",
    "            # Начальная и конечная точки отрезка\n",
    "            u, v = path[i], path[i + 1]\n",
    "            point1 = (G.nodes[u][\"y\"], G.nodes[u][\"x\"])\n",
    "            point2 = (G.nodes[v][\"y\"], G.nodes[v][\"x\"])\n",
    "\n",
    "            # Расстояние между узлами\n",
    "            edge_length = gd(point1, point2).meters\n",
    "            direction_bearing = ox.bearing.calculate_bearing(\n",
    "                point1[0], point1[1], point2[0], point2[1]\n",
    "            )\n",
    "\n",
    "            # Добавление точек через случайное расстояние между 20 и 60 метров\n",
    "            current_dist = 0\n",
    "            previous_node = u\n",
    "            while current_dist < edge_length:\n",
    "                # Случайное расстояние до следующей точки\n",
    "                random_dist = random.uniform(self.__min_segment, self.__max_segment)\n",
    "                current_dist += random_dist\n",
    "\n",
    "                if current_dist >= edge_length:\n",
    "                    break\n",
    "\n",
    "                # Вычисление промежуточной точки\n",
    "                new_point = gd(meters=current_dist).destination(\n",
    "                    point1, direction_bearing\n",
    "                )\n",
    "                new_lat, new_lon = new_point.latitude, new_point.longitude\n",
    "\n",
    "                # Случайное отклонение влево или вправо\n",
    "                offset_direction = direction_bearing + (\n",
    "                    90 if random.choice([True, False]) else -90\n",
    "                )\n",
    "                offset_dist = random.uniform(self.__min_offset, self.__max_offset)\n",
    "                offset_point = gd(meters=offset_dist).destination(\n",
    "                    (new_lat, new_lon), offset_direction\n",
    "                )\n",
    "                offset_lat, offset_lon = (offset_point.latitude, offset_point.longitude)\n",
    "\n",
    "                # Добавление новой вершины и её координат\n",
    "                new_node = max(G.nodes) + 1\n",
    "                G.add_node(new_node, y=offset_lat, x=offset_lon)\n",
    "                new_nodes.append(new_node)\n",
    "\n",
    "                # Добавление ребра между новой точкой и предыдущей точкой\n",
    "                G.add_edge(previous_node, new_node, length=random_dist)\n",
    "                G.add_edge(\n",
    "                    new_node, v, length=edge_length - current_dist\n",
    "                )  # Связь с основным маршрутом\n",
    "\n",
    "                previous_node = new_node  # Сместить начальную точку для следующего шага\n",
    "            new_nodes.append(path[i + 1])\n",
    "\n",
    "        false_route = [(G.nodes[n][\"x\"], G.nodes[n][\"y\"]) for n in new_nodes]\n",
    "        return G, false_route\n",
    "\n",
    "    def save_main_route(self) -> tuple:\n",
    "        \"\"\"Генерация и сохранение исходного маршрута\n",
    "\n",
    "        Args: _\n",
    "        \"\"\"\n",
    "        keys = list(self.graph.nodes.keys()).copy()\n",
    "        node_ids = []\n",
    "\n",
    "        while len(node_ids) < self.__min_route_len or len(node_ids) > self.__max_route_len:\n",
    "            try:\n",
    "                start = random.choice(keys)\n",
    "                keys.remove(start)\n",
    "                end = random.choice(keys)\n",
    "                # Поиск кратчайшего пути\n",
    "                node_ids = nx.astar_path(self.graph, start, end, weight=\"length\")\n",
    "            except nx.NetworkXNoPath:\n",
    "                pass\n",
    "        main_route = [(self.graph.nodes[n][\"x\"], self.graph.nodes[n][\"y\"])\n",
    "                      for n in node_ids]\n",
    "        return node_ids, main_route\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_cumulative_distances(route: \"np.ndarray\"):\n",
    "        distances = [0]  # Начинаем с 0 элемента\n",
    "        for i in range(1, len(route)):\n",
    "            lon1, lat1 = route[i - 1]\n",
    "            lon2, lat2 = route[i]\n",
    "            distance = haversine((lon1, lat1), (lon2, lat2), unit=Unit.METERS)\n",
    "            distances.append(distances[-1] + distance)\n",
    "        return np.array(distances)\n",
    "\n",
    "    # Функция для интерполяции маршрута\n",
    "\n",
    "    def make_equal(self, route: list, num_points: int) -> list:\n",
    "        route = np.array(route)\n",
    "        # Вычисляем кумулятивное расстояние\n",
    "        distances = self.calculate_cumulative_distances(route)\n",
    "\n",
    "        # Создаем интерполяционные функции для широты и долготы\n",
    "        interpolation_func_lon = interp1d(distances, route[:, 0], kind='linear')\n",
    "        interpolation_func_lat = interp1d(distances, route[:, 1], kind='linear')\n",
    "\n",
    "        new_distances = np.linspace(0, distances[-1], num_points)\n",
    "\n",
    "        new_lon = interpolation_func_lon(new_distances)\n",
    "        new_lat = interpolation_func_lat(new_distances)\n",
    "        new_route = list(np.column_stack((new_lon, new_lat)))\n",
    "        new_route = [tuple(point) for point in new_route]\n",
    "        return new_route\n",
    "\n",
    "    def save_data(self) -> None:\n",
    "        for i in range(self.__data_amount):\n",
    "            route_ids, main_route = self.save_main_route()\n",
    "            _, false_route = self.save_false_route(route_ids)\n",
    "\n",
    "            main_route = self.make_equal(main_route, len(false_route))\n",
    "            self.data['y'].append(main_route)\n",
    "            self.data['X'].append(false_route)\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"Сделано {i + 1}/{self.__data_amount} маршрутов\")\n"
   ],
   "metadata": {
    "id": "6h9wt_KDgiAI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Функции для запуска примера"
   ],
   "metadata": {
    "id": "u73_9yRs1KUE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В качестве примера будут созданы 3 html-файла в папке example:\n",
    "- *input* - входной маршрут\n",
    "- *target* - целевой маршрут\n",
    "- *predict* - предсказанный моделью маршрут"
   ],
   "metadata": {
    "id": "SOrS10Ci4b3M"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def save_route(points: list, save_folder: str, name: str) -> None:\n",
    "    # Создаем карту, центрированную на первой точке\n",
    "    points = [(point[1], point[0]) for point in points]\n",
    "    plot = folium.Map(location=points[0], zoom_start=15)\n",
    "\n",
    "    # Соединяем точки линией (маршрут)\n",
    "    folium.PolyLine(points, color=\"red\", weight=2, opacity=1).add_to(plot)\n",
    "\n",
    "    # Сохраняем карту в HTML-файл и открываем его\n",
    "    plot.save(f\"{save_folder}/{name}.html\")\n",
    "\n",
    "\n",
    "def lstm_test(save_folder: str) -> None:\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    test_model = torch.load('lstm_model.pth', weights_only=False)\n",
    "    test_model.eval()\n",
    "\n",
    "    sc = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    place_bbox = [39.0296, 51.7806, 39.3414, 51.5301]\n",
    "    generator = RouteGenerator(place_bbox=place_bbox)\n",
    "    G, result = generator.graph, generator.save_main_route()\n",
    "    main_ids, main_coords = result\n",
    "    G_false, false_coords = generator.save_false_route(main_ids)\n",
    "\n",
    "    main_coords = generator.make_equal(main_coords, len(false_coords))\n",
    "\n",
    "    save_route(main_coords, save_folder, \"target\")\n",
    "    save_route(false_coords, save_folder, \"input\")\n",
    "\n",
    "    false_coords = torch.tensor(sc.fit_transform(false_coords), dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        predict = test_model(false_coords)\n",
    "    predict = sc.inverse_transform(predict.detach().numpy())\n",
    "    print(predict)\n",
    "    save_route(predict, save_folder, \"predict\")\n",
    "    print(f\"MSE: {mean_squared_error(predict, main_coords)} \\t MAE: {mean_absolute_error(predict, main_coords)}\")\n",
    "\n"
   ],
   "metadata": {
    "id": "1KgyHYtKgVDI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Запустим пример и сохраним файлы в папку example."
   ],
   "metadata": {
    "id": "W_tm9JsC1dLa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "lstm_test(\"example\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "IU7xLgQtg0c4",
    "outputId": "1187f24b-ddb7-454a-9acc-59ff4fa1d227"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[39.244995 51.673054]\n",
      " [39.24536  51.675926]\n",
      " [39.24519  51.67606 ]\n",
      " [39.24539  51.675865]\n",
      " [39.245564 51.675636]\n",
      " [39.245365 51.675484]\n",
      " [39.24521  51.67535 ]\n",
      " [39.24528  51.675312]\n",
      " [39.245274 51.675266]\n",
      " [39.245483 51.675396]\n",
      " [39.245926 51.6756  ]\n",
      " [39.246265 51.67552 ]\n",
      " [39.24671  51.67573 ]\n",
      " [39.2469   51.675735]\n",
      " [39.246994 51.675697]\n",
      " [39.2473   51.675816]\n",
      " [39.247784 51.675865]\n",
      " [39.248158 51.675728]\n",
      " [39.248726 51.675842]\n",
      " [39.249126 51.675797]\n",
      " [39.249634 51.675816]\n",
      " [39.24995  51.67579 ]\n",
      " [39.25026  51.67569 ]\n",
      " [39.25054  51.675518]\n",
      " [39.250885 51.6752  ]\n",
      " [39.25148  51.67513 ]\n",
      " [39.25173  51.67488 ]\n",
      " [39.251755 51.674442]\n",
      " [39.25151  51.67383 ]\n",
      " [39.251686 51.67325 ]\n",
      " [39.251583 51.672787]\n",
      " [39.25119  51.67222 ]\n",
      " [39.25105  51.671696]\n",
      " [39.25113  51.67133 ]\n",
      " [39.251095 51.670864]\n",
      " [39.25066  51.67031 ]\n",
      " [39.250587 51.66987 ]\n",
      " [39.250614 51.669373]\n",
      " [39.25038  51.668877]\n",
      " [39.250023 51.66836 ]\n",
      " [39.25007  51.667953]\n",
      " [39.2498   51.667606]\n",
      " [39.249443 51.66718 ]\n",
      " [39.249542 51.666756]\n",
      " [39.249466 51.66641 ]\n",
      " [39.249226 51.666103]\n",
      " [39.248707 51.66569 ]\n",
      " [39.248688 51.665447]\n",
      " [39.248604 51.665222]\n",
      " [39.248543 51.665   ]\n",
      " [39.248463 51.664604]\n",
      " [39.248146 51.664295]\n",
      " [39.24783  51.663906]\n",
      " [39.247593 51.66345 ]\n",
      " [39.247726 51.662987]\n",
      " [39.247383 51.662556]\n",
      " [39.246895 51.662125]\n",
      " [39.246803 51.6617  ]\n",
      " [39.246857 51.66127 ]\n",
      " [39.246315 51.660828]\n",
      " [39.24631  51.66044 ]\n",
      " [39.245995 51.660122]\n",
      " [39.246212 51.65979 ]\n",
      " [39.24605  51.659542]\n",
      " [39.245907 51.65931 ]\n",
      " [39.245712 51.65903 ]\n",
      " [39.245583 51.658794]\n",
      " [39.245308 51.658722]\n",
      " [39.245125 51.658527]\n",
      " [39.245228 51.65822 ]\n",
      " [39.245144 51.658005]\n",
      " [39.245102 51.65778 ]\n",
      " [39.24481  51.65746 ]\n",
      " [39.244297 51.657295]\n",
      " [39.24417  51.656998]\n",
      " [39.244316 51.65676 ]\n",
      " [39.244053 51.656612]\n",
      " [39.24392  51.65642 ]\n",
      " [39.243744 51.65609 ]\n",
      " [39.243355 51.6558  ]\n",
      " [39.24335  51.655457]\n",
      " [39.24292  51.655197]\n",
      " [39.242992 51.65507 ]\n",
      " [39.24269  51.654736]\n",
      " [39.24259  51.654278]\n",
      " [39.242783 51.653893]\n",
      " [39.24269  51.653618]\n",
      " [39.242416 51.65346 ]\n",
      " [39.242283 51.653103]\n",
      " [39.241753 51.652702]\n",
      " [39.241783 51.652306]\n",
      " [39.24135  51.65211 ]\n",
      " [39.24132  51.651855]\n",
      " [39.241558 51.65153 ]\n",
      " [39.241177 51.651268]\n",
      " [39.241356 51.65088 ]\n",
      " [39.240917 51.65035 ]\n",
      " [39.241013 51.649746]\n",
      " [39.24079  51.6492  ]\n",
      " [39.24024  51.648693]\n",
      " [39.240128 51.648235]\n",
      " [39.239662 51.648   ]\n",
      " [39.23953  51.647736]\n",
      " [39.23932  51.647327]\n",
      " [39.239353 51.647007]\n",
      " [39.239464 51.646786]\n",
      " [39.239285 51.646297]\n",
      " [39.23945  51.645927]\n",
      " [39.2392   51.645657]\n",
      " [39.23878  51.64536 ]\n",
      " [39.23884  51.64496 ]\n",
      " [39.238422 51.644627]\n",
      " [39.238583 51.64416 ]\n",
      " [39.238503 51.643826]\n",
      " [39.2383   51.64352 ]\n",
      " [39.238113 51.643257]\n",
      " [39.23809  51.642967]\n",
      " [39.237736 51.642673]\n",
      " [39.237835 51.64233 ]\n",
      " [39.23739  51.642006]\n",
      " [39.237385 51.64172 ]\n",
      " [39.237644 51.641396]\n",
      " [39.237457 51.641056]\n",
      " [39.237076 51.640766]\n",
      " [39.236588 51.640423]\n",
      " [39.23672  51.6401  ]\n",
      " [39.236168 51.63967 ]\n",
      " [39.236115 51.63921 ]\n",
      " [39.236134 51.638847]\n",
      " [39.236042 51.63843 ]\n",
      " [39.23552  51.63798 ]\n",
      " [39.235676 51.637592]\n",
      " [39.23529  51.637173]\n",
      " [39.235397 51.636723]\n",
      " [39.23525  51.636364]\n",
      " [39.234818 51.63597 ]\n",
      " [39.23487  51.6355  ]\n",
      " [39.234444 51.6351  ]\n",
      " [39.234493 51.634678]\n",
      " [39.234165 51.634163]\n",
      " [39.234127 51.633488]\n",
      " [39.233707 51.63275 ]\n",
      " [39.233837 51.632   ]\n",
      " [39.233784 51.631344]\n",
      " [39.233547 51.63082 ]\n",
      " [39.23354  51.630356]\n",
      " [39.233353 51.62998 ]\n",
      " [39.23333  51.62966 ]\n",
      " [39.232887 51.62919 ]\n",
      " [39.232605 51.628754]\n",
      " [39.23247  51.62831 ]\n",
      " [39.232323 51.62797 ]\n",
      " [39.232178 51.627632]\n",
      " [39.231987 51.62728 ]\n",
      " [39.23215  51.62704 ]\n",
      " [39.23232  51.626778]\n",
      " [39.232174 51.626293]\n",
      " [39.23239  51.625786]\n",
      " [39.233013 51.62556 ]\n",
      " [39.2332   51.625328]\n",
      " [39.23296  51.624798]\n",
      " [39.233032 51.624428]\n",
      " [39.23325  51.624046]\n",
      " [39.2338   51.623943]\n",
      " [39.23402  51.623577]\n",
      " [39.23428  51.623234]\n",
      " [39.234146 51.622677]\n",
      " [39.23431  51.622387]\n",
      " [39.234665 51.622265]\n",
      " [39.234623 51.621838]\n",
      " [39.234936 51.621532]\n",
      " [39.235443 51.62144 ]\n",
      " [39.23551  51.62126 ]\n",
      " [39.23536  51.620945]\n",
      " [39.235447 51.620716]\n",
      " [39.235874 51.620636]\n",
      " [39.236206 51.62039 ]\n",
      " [39.236378 51.620132]\n",
      " [39.236126 51.61984 ]\n",
      " [39.23616  51.619743]\n",
      " [39.236202 51.619556]\n",
      " [39.236477 51.619457]\n",
      " [39.23684  51.619453]\n",
      " [39.236984 51.61925 ]\n",
      " [39.237316 51.619186]\n",
      " [39.237385 51.618965]\n",
      " [39.237225 51.618797]\n",
      " [39.237343 51.61869 ]\n",
      " [39.23724  51.618374]\n",
      " [39.237644 51.61829 ]\n",
      " [39.23778  51.617958]\n",
      " [39.237885 51.617664]\n",
      " [39.23773  51.617268]\n",
      " [39.23801  51.617245]\n",
      " [39.238293 51.617123]\n",
      " [39.238285 51.616817]\n",
      " [39.237965 51.616386]\n",
      " [39.237846 51.61618 ]\n",
      " [39.23806  51.6161  ]\n",
      " [39.238026 51.61581 ]\n",
      " [39.23827  51.61562 ]\n",
      " [39.2382   51.615368]\n",
      " [39.23822  51.61517 ]\n",
      " [39.238266 51.61487 ]\n",
      " [39.238003 51.614418]\n",
      " [39.2381   51.614124]\n",
      " [39.238365 51.61391 ]\n",
      " [39.238136 51.61341 ]\n",
      " [39.238113 51.61311 ]\n",
      " [39.23824  51.61304 ]\n",
      " [39.238194 51.61276 ]\n",
      " [39.23827  51.612526]\n",
      " [39.23853  51.61236 ]\n",
      " [39.238636 51.612133]\n",
      " [39.238544 51.611774]\n",
      " [39.238266 51.611443]\n",
      " [39.23847  51.611336]\n",
      " [39.238686 51.61111 ]\n",
      " [39.23861  51.61089 ]\n",
      " [39.238842 51.61086 ]\n",
      " [39.239388 51.610867]\n",
      " [39.24003  51.611008]\n",
      " [39.240353 51.610783]\n",
      " [39.240856 51.6108  ]\n",
      " [39.241356 51.610855]\n",
      " [39.24162  51.610626]\n",
      " [39.24204  51.610687]\n",
      " [39.242355 51.61051 ]\n",
      " [39.242718 51.610252]\n",
      " [39.243    51.610096]\n",
      " [39.24338  51.610134]\n",
      " [39.2438   51.60998 ]\n",
      " [39.244083 51.6097  ]\n",
      " [39.244236 51.60946 ]\n",
      " [39.244183 51.60898 ]\n",
      " [39.243988 51.60849 ]\n",
      " [39.243618 51.608128]\n",
      " [39.243755 51.60797 ]\n",
      " [39.24372  51.60766 ]\n",
      " [39.243637 51.607174]\n",
      " [39.243477 51.606087]\n",
      " [39.24375  51.604527]\n",
      " [39.243664 51.603962]\n",
      " [39.243046 51.609943]]\n",
      "MSE: 2.710105945880059e-06 \t MAE: 0.0013137019705027342\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Графовые нейронные сети"
   ],
   "metadata": {
    "id": "V-AHe4vg_inD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ансамбли моделей"
   ],
   "metadata": {
    "id": "0mCzSwT0_lNF"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:13:31.003976Z",
     "start_time": "2025-03-25T23:13:31.000113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "import geopandas as gpd"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:11:22.018406Z",
     "start_time": "2025-03-25T23:11:22.012554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GATxRNN(nn.Module):\n",
    "    \"\"\"\"\n",
    "    Класс модели, которая использует графовую нейронную сеть с механизмом внимания\n",
    "    и рекуррентную нейронную сеть на основе seq2seq\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        # Кодировщик координат (преобразует (lat, lon) в эмбеддинг)\n",
    "        self.coord_encoder = nn.Linear(2, hidden_dim)\n",
    "\n",
    "        # Кодировщик графа (GNN)\n",
    "        self.gnn = GATConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Механизм внимания между точками и графом\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=4)\n",
    "\n",
    "        # Seq2seq, предсказывает следующий узел\n",
    "        self.decoder = nn.LSTM(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, graph_data, route_coords):\n",
    "        route_emb = self.coord_encoder(route_coords)  # [seq_len, hidden_dim]\n",
    "        node_emb = self.gnn(graph_data.x, graph_data.edge_index)  # [num_nodes, hidden_dim]\n",
    "\n",
    "        # 3. Сопоставляем точки маршрута с узлами графа через внимание\n",
    "        corrected_emb, _ = self.attention(\n",
    "            route_emb, node_emb, node_emb\n",
    "        )\n",
    "\n",
    "        # 4. Декодируем последовательность узлов\n",
    "        output, _ = self.decoder(corrected_emb)\n",
    "        return output  # [seq_len, hidden_dim]\n"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:11:41.847512Z",
     "start_time": "2025-03-25T23:11:41.706007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Параметры модели\n",
    "hidden_dim = 32\n",
    "batch_size = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# создаём модель\n",
    "model = GATxRNN(hidden_dim).to(device)\n",
    "\n",
    "# функция потерь и оптимизатор\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "loss_fn = nn.CTCLoss()"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:07:05.061750Z",
     "start_time": "2025-03-25T23:07:03.479814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка графа дорог Воронежа\n",
    "datapath = \"training data\"\n",
    "\n",
    "# Атрибуты вершины: координаты, id, кол-вол улиц\n",
    "nodes = gpd.read_file(os.path.join(datapath, \"nodes.csv\"), encoding=\"utf8\")\n",
    "nodes = nodes.iloc[:, :4]\n",
    "nodes_type = {'osmid': 'int64', 'street_count': 'int64',\n",
    "              'y': 'float64', 'x': 'float64'}\n",
    "nodes = nodes.astype(nodes_type)\n",
    "\n",
    "edges = gpd.read_file(os.path.join(datapath, \"edges.csv\"), encoding=\"utf8\")\n",
    "edge_index = edges[['u', 'v']]\n",
    "edge_index_type = {'u': 'int64', 'v': 'int64'}\n",
    "edge_index = edge_index.astype(edge_index_type)\n",
    "\n",
    "# Атрибуты ребра: id, кол-во полос, односторонность, реверсивность, длина\n",
    "edge_attr = edges[['oneway', 'reversed', 'length']]\n",
    "edge_attr_type = {'oneway': bool, 'reversed': bool, 'length': 'float32'}\n",
    "edge_attr = edge_attr.astype(edge_attr_type)\n",
    "edge_attr['oneway'] = edge_attr['oneway'].astype(int)\n",
    "edge_attr['reversed'] = edge_attr['oneway'].astype(int)"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:07:16.042791Z",
     "start_time": "2025-03-25T23:07:16.030424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nodes_t = torch.tensor(nodes.values)\n",
    "edge_index_t = torch.tensor(edge_index.values)\n",
    "edge_attr_t = torch.tensor(edge_attr.values)"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T23:13:48.474857Z",
     "start_time": "2025-03-25T23:13:48.470836Z"
    }
   },
   "cell_type": "code",
   "source": "graph = Data(x=nodes_t, edge_index=edge_index_t, edge_attr=edge_attr_t)",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Остаётся только загрузить граф в dataloader/dataset, чтобы можно было его передавать модели"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_epochs = 50  # Количество эпох при обучении\n",
    "train_hist = []\n",
    "test_hist = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:  # выборка разделяется на части (батчи)\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        predictions = model(batch_X)\n",
    "        loss = loss_fn(predictions, batch_y)  # для каждого батча считается функция потерь\n",
    "\n",
    "        # обратное распространение ошибки\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    train_hist.append(average_loss)\n",
    "\n",
    "    # расчёты для тестовых бачтей\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0.0\n",
    "\n",
    "        for batch_X_test, batch_y_test in test_loader:\n",
    "            batch_X_test, batch_y_test = batch_X_test.to(device), batch_y_test.to(device)\n",
    "            predictions_test = model(batch_X_test)\n",
    "            test_loss = loss_fn(predictions_test, batch_y_test)\n",
    "\n",
    "            total_test_loss += test_loss.item()\n",
    "\n",
    "        average_test_loss = total_test_loss / len(test_loader)\n",
    "        test_hist.append(average_test_loss)\n",
    "\n",
    "    print(\n",
    "        f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}, Test Loss: {average_test_loss:.4f}')\n"
   ]
  }
 ]
}
