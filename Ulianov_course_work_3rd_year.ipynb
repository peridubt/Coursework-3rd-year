{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт библиотек"
      ],
      "metadata": {
        "id": "8ApPJ6x5wopM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install osmnx\n",
        "!pip install haversine\n",
        "!pip install geopy\n",
        "!pip install folium\n",
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "_mdpqm6e0VuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09520fbb-6171-4f9e-e1b8-8c534dc93e4c",
        "collapsed": true
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: osmnx in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: geopandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from osmnx) (1.0.1)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.11/dist-packages (from osmnx) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.32.3)\n",
            "Requirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.11/dist-packages (from osmnx) (2.1.0)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (24.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas>=1.0->osmnx) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->osmnx) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->osmnx) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n",
            "Requirement already satisfied: haversine in /usr/local/lib/python3.11/dist-packages (2.9.0)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.11/dist-packages (0.19.5)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from folium) (0.8.1)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from folium) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from folium) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from folium) (2.32.3)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from folium) (2025.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (2025.1.31)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_97UifVTjeQl",
        "ExecuteTime": {
          "end_time": "2025-04-01T16:43:59.032569Z",
          "start_time": "2025-04-01T16:43:34.553877Z"
        }
      },
      "source": [
        "import torch  # pytorch\n",
        "import json  # чтение json файла\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim  # регуляризация модели\n",
        "from torch.nn.utils.rnn import pad_sequence  # выраванивание последовательностей\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split  # разделение выборки на test/train\n",
        "from sklearn.preprocessing import MinMaxScaler  # нормализация данных\n",
        "from torch.masked import masked_tensor\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import osmnx as ox  # библиотека для работы с OSM\n",
        "import networkx as nx  # для работы с графами местностей\n",
        "from geopy.distance import geodesic as gd\n",
        "\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.data import Data, Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "import geopandas as gpd\n",
        "\n",
        "from haversine import haversine, Unit  # вычисление расстояний между точками кординат\n",
        "from scipy.interpolate import interp1d  # интерполяция маршрутов\n",
        "\n",
        "import os\n",
        "import folium  # для построения html-запросов через leafnet и вывода маршрутов\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error  # метрики для модели"
      ],
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка и предобработка данных"
      ],
      "metadata": {
        "id": "x7Cnhx5vzQ_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подгрузка выборки в виде последовательностей координат в количестве 10000 штук (routes.json)"
      ],
      "metadata": {
        "id": "bKdw4s2U0mth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1VYI0Mi5XTASGDon33RNMjdMlkCKynA0k"
      ],
      "metadata": {
        "id": "bu3oCSUZ0mYX",
        "ExecuteTime": {
          "end_time": "2025-03-25T18:34:55.628543Z",
          "start_time": "2025-03-25T18:34:55.572750Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e64f30-53d8-4f20-9503-e8d16d1e1e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1VYI0Mi5XTASGDon33RNMjdMlkCKynA0k\n",
            "From (redirected): https://drive.google.com/uc?id=1VYI0Mi5XTASGDon33RNMjdMlkCKynA0k&confirm=t&uuid=b923b059-23aa-471c-a533-e8b992ff02c9\n",
            "To: /content/routes.json\n",
            "100% 286M/286M [00:02<00:00, 106MB/s]\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка данных выборки из файла"
      ],
      "metadata": {
        "id": "pRLSncLRwteF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка маршрутов\n",
        "routes_path = \"routes.json\"\n",
        "with (open(routes_path, 'r', encoding='utf-8')) as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "X, y = data['X'], data['y']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    train_size=0.8,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "ryDnZ7uZjlX1",
        "ExecuteTime": {
          "end_time": "2025-04-01T16:44:20.067234Z",
          "start_time": "2025-04-01T16:44:13.620963Z"
        }
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "Происходит выравнивание последовательностей в соответствии с самой длинной последовательностью и их преобразование в тензоры, далее следует нормализация в отрезок [-1; 1]. После выравнивания лишние элементы будут иметь координаты (0, 0). Затем данные загружаются в dataset и dataloader\n",
        "\n",
        "Размер одного батча (отрезка) при обучении моделей = 64"
      ],
      "metadata": {
        "id": "EPgo3PUZyE43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = MinMaxScaler(feature_range=(-1, 1))\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "iA5EXTlDya2s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [torch.tensor(sc.fit_transform(seq), dtype=torch.float32) for seq in X_train]\n",
        "y_train = [torch.tensor(sc.fit_transform(seq), dtype=torch.float32) for seq in y_train]\n",
        "X_train_pad = pad_sequence(X_train, batch_first=True)\n",
        "y_train_pad = pad_sequence(y_train, batch_first=True)\n",
        "\n",
        "X_test = [torch.tensor(sc.fit_transform(seq), dtype=torch.float32) for seq in X_test]\n",
        "y_test = [torch.tensor(sc.fit_transform(seq), dtype=torch.float32) for seq in y_test]\n",
        "X_test_pad = pad_sequence(X_test, batch_first=True)\n",
        "y_test_pad = pad_sequence(y_test, batch_first=True)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_pad, y_train_pad)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataset = TensorDataset(X_test_pad, y_test_pad)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "-Bk9CSmBjtkY",
        "ExecuteTime": {
          "end_time": "2025-04-01T21:12:17.585464Z",
          "start_time": "2025-04-01T21:12:08.194421Z"
        }
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Рекуррентные нейронные сети"
      ],
      "metadata": {
        "id": "isXu_940_Hl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Простейшая LSTM"
      ],
      "metadata": {
        "id": "J6Fy9sNXTyi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # проходим через LSTM\n",
        "        out, _ = self.lstm(x)\n",
        "        # проходим через линейный слой\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ZwPmCw0WT8DE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка обученной модели (опционально)**"
      ],
      "metadata": {
        "id": "o7el3OJYytXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно пропустить этап с обучением и сразу загрузить обученную модель (lstm_model.pth) с установившимися параметрами и перейти к шагу с [примером](https://colab.research.google.com/drive/1l7Huzgg3UWtsEOXKwKq9BCVu36yVRGG-#scrollTo=q4jUyVBLW1Ep&line=1&uniqifier=1). Подобное можно проделать и с остальными моделями."
      ],
      "metadata": {
        "id": "XrM9AMgQ3O9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Параметры модели"
      ],
      "metadata": {
        "id": "R6obs4cEzA9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры модели\n",
        "input_size = 2\n",
        "hidden_size = 64\n",
        "output_size = 2\n",
        "num_layers = 2\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = LSTM(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "# функция потерь и оптимизатор\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IASWIG0U6r5Y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение модели"
      ],
      "metadata": {
        "id": "qIHnoQyozEJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50  # Количество эпох при обучении\n",
        "train_hist = []\n",
        "test_hist = []\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    model.train()\n",
        "    for batch_X, batch_y in train_loader:  # выборка разделяется на части (батчи)\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        predictions = model(batch_X)\n",
        "        loss = loss_fn(predictions, batch_y)  # для каждого батча считается функция потерь\n",
        "\n",
        "        # обратное распространение ошибки\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    train_hist.append(average_loss)\n",
        "\n",
        "    # расчёты для тестовых бачтей\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_test_loss = 0.0\n",
        "\n",
        "        for batch_X_test, batch_y_test in test_loader:\n",
        "            batch_X_test, batch_y_test = batch_X_test.to(device), batch_y_test.to(device)\n",
        "            predictions_test = model(batch_X_test)\n",
        "            test_loss = loss_fn(predictions_test, batch_y_test)\n",
        "\n",
        "            total_test_loss += test_loss.item()\n",
        "\n",
        "        average_test_loss = total_test_loss / len(test_loader)\n",
        "        test_hist.append(average_test_loss)\n",
        "\n",
        "    print(\n",
        "        f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}, Test Loss: {average_test_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Fy8wp-Wc6dYY",
        "outputId": "3276202c-e2f3-45e3-d41e-bf66db3566d7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5caf90c11e2d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# обратное распространение ошибки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Графики функции ошибки для простой LSTM модели"
      ],
      "metadata": {
        "id": "e-duTrH16S2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_hist, label=\"Training loss\")\n",
        "plt.plot(test_hist, label=\"Test loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "z2Z1f0wa6Sbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, './lstm.pth')"
      ],
      "metadata": {
        "id": "w4Yg9cf-6lK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Двунаправленная LSTM"
      ],
      "metadata": {
        "id": "iqxMaMolz8-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Слои LSTM являются двунаправленными, т.е. они могут работать как с данными из прошлого, так и с предсказанными, отсюда для линейного слоя размер скрытого слоя увеличен в 2 раза. Также был добавлен слой dropout, который отвечает за отключение неиспользуемых нейронов"
      ],
      "metadata": {
        "id": "7JYK6an-wqJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BidirectionalLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(BidirectionalLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                            batch_first=True, dropout=0.2, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # проходим через LSTM\n",
        "        out, _ = self.lstm(x)\n",
        "        # проходим через линейный слой\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "0d-8cn4djhzk",
        "ExecuteTime": {
          "end_time": "2025-04-01T16:44:06.545001Z",
          "start_time": "2025-04-01T16:44:06.540206Z"
        }
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка обученной модели (опционально)**"
      ],
      "metadata": {
        "id": "uOdXM18J3Ijx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 16Hbvud9yHTT22XZ4WLZ0g4JfWkjsikx1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KX19Zy53Jhl",
        "outputId": "7df9ae0e-c0fa-4edd-83ff-c46c33e4de59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16Hbvud9yHTT22XZ4WLZ0g4JfWkjsikx1\n",
            "To: /content/lstm_model.pth\n",
            "\r  0% 0.00/546k [00:00<?, ?B/s]\r100% 546k/546k [00:00<00:00, 13.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Параметры модели"
      ],
      "metadata": {
        "id": "xcBUr1VV0D8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для модели были выбраны следующие параметры:\n",
        "- входной и выходной размеры = 2, т.к. последовательность имеет размерность N x 2, т.е. ширина и долгота\n",
        "- размер скрытого слоя LSTM = 64\n",
        "- число слоёв LSTM = 2\n",
        "\n",
        "Другие характеристики:\n",
        "- В качестве функции ошибки была выбрана среднеквадратическая ошибка (MSE).\n",
        "- Для регуляризации был выбран оптимизатор Adam, learning rate = 0.0005."
      ],
      "metadata": {
        "id": "-y19UyUAw1q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры модели\n",
        "input_size = 2\n",
        "hidden_size = 64\n",
        "output_size = 2\n",
        "num_layers = 1\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# создаём модель\n",
        "model = BidirectionalLSTM(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "# функция потерь и оптимизатор\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
        "\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "J00_HHpNjnSs",
        "ExecuteTime": {
          "end_time": "2025-04-01T21:11:59.323198Z",
          "start_time": "2025-04-01T21:11:59.312934Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение модели"
      ],
      "metadata": {
        "id": "-nvec7ZpzWFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На обучение выделено 10 эпох."
      ],
      "metadata": {
        "id": "yimv0P4eykzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50  # Количество эпох при обучении\n",
        "train_hist = []\n",
        "test_hist = []\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    model.train()\n",
        "    for batch_X, batch_y in train_loader:  # выборка разделяется на части (батчи)\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        predictions = model(batch_X)\n",
        "        loss = loss_fn(predictions, batch_y)  # для каждого батча считается функция потерь\n",
        "\n",
        "        # обратное распространение ошибки\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    train_hist.append(average_loss)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_test_loss = 0.0\n",
        "\n",
        "        for batch_X_test, batch_y_test in test_loader:\n",
        "            batch_X_test, batch_y_test = batch_X_test.to(device), batch_y_test.to(device)\n",
        "            predictions_test = model(batch_X_test)\n",
        "            test_loss = loss_fn(predictions_test, batch_y_test)\n",
        "\n",
        "            total_test_loss += test_loss.item()\n",
        "\n",
        "        average_test_loss = total_test_loss / len(test_loader)\n",
        "        test_hist.append(average_test_loss)\n",
        "\n",
        "    print(\n",
        "        f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}, Test Loss: {average_test_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbsdzTfjjxDq",
        "outputId": "ce7cb97e-0f4b-423b-9620-f6d0417d2b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Training Loss: 0.0203, Test Loss: 0.0040\n",
            "Epoch [2/10] - Training Loss: 0.0040, Test Loss: 0.0037\n",
            "Epoch [3/10] - Training Loss: 0.0037, Test Loss: 0.0036\n",
            "Epoch [4/10] - Training Loss: 0.0036, Test Loss: 0.0035\n",
            "Epoch [5/10] - Training Loss: 0.0035, Test Loss: 0.0034\n",
            "Epoch [6/10] - Training Loss: 0.0035, Test Loss: 0.0034\n",
            "Epoch [7/10] - Training Loss: 0.0033, Test Loss: 0.0033\n",
            "Epoch [8/10] - Training Loss: 0.0032, Test Loss: 0.0032\n",
            "Epoch [9/10] - Training Loss: 0.0030, Test Loss: 0.0030\n",
            "Epoch [10/10] - Training Loss: 0.0029, Test Loss: 0.0028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим график функции ошибки для тренировочных и тестовых данных."
      ],
      "metadata": {
        "id": "-yuGEiZR5Op9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_hist, label=\"Training loss\")\n",
        "plt.plot(test_hist, label=\"Test loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Ea4AU7Rw5TO9",
        "outputId": "65741b86-871e-45e8-f7df-09384aeb57fc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры модели можно сохранить в отдельном файле"
      ],
      "metadata": {
        "id": "-U3JtW98y_T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, './lstm_bidir.pth')"
      ],
      "metadata": {
        "id": "BOQeq2XOl1Rx",
        "ExecuteTime": {
          "end_time": "2025-04-01T23:57:33.412605Z",
          "start_time": "2025-04-01T23:57:33.400036Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Улучшенная модель LSTM"
      ],
      "metadata": {
        "id": "v08WpXeYTm9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "        super(EnhancedLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Улучшенная LSTM с:\n",
        "        # - Больше слоев\n",
        "        # - Layer normalization\n",
        "        # - Dropout между слоями\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=0.3 if num_layers > 1 else 0,\n",
        "            bidirectional=False\n",
        "        )\n",
        "\n",
        "        # Layer normalization для стабилизации LSTM выходов\n",
        "        self.ln1 = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        # Дополнительные полносвязные слои с residual connection\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.ln2 = nn.LayerNorm(hidden_size)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # Инициализация весов\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.lstm.named_parameters():\n",
        "            if 'weight_ih' in name:\n",
        "                nn.init.xavier_uniform_(param.data)\n",
        "            elif 'weight_hh' in name:\n",
        "                nn.init.orthogonal_(param.data)\n",
        "            elif 'bias' in name:\n",
        "                param.data.fill_(0)\n",
        "                # Устанавливаем forget gate bias в 1\n",
        "                n = param.size(0)\n",
        "                param.data[(n // 4):(n // 2)].fill_(1)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.zeros_(self.fc1.bias)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.zeros_(self.fc2.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM layers\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.ln1(out)\n",
        "\n",
        "        # Первый полносвязный слой с residual connection\n",
        "        residual = out\n",
        "        out = self.fc1(out)\n",
        "        out = self.ln2(out)\n",
        "        out = F.leaky_relu(out, 0.1)\n",
        "        out = self.dropout(out)\n",
        "        out = out + residual[:, :, :self.hidden_size]  # residual connection\n",
        "\n",
        "        # Final output layer\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"Инференс для одного маршрута\"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            if isinstance(x, (list, np.ndarray)):\n",
        "                x = torch.FloatTensor(x).unsqueeze(0)  # add batch dim\n",
        "            return self.forward(x).squeeze(0).cpu().numpy()"
      ],
      "metadata": {
        "id": "geKs0zv0Trb_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка обученной модели (опционально)**"
      ],
      "metadata": {
        "id": "2_VBXBrbzv6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Параметры модели"
      ],
      "metadata": {
        "id": "ofGNyxEezG-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры модели\n",
        "input_size = 2\n",
        "hidden_size = 128\n",
        "output_size = 2\n",
        "num_layers = 2\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# создаём модель\n",
        "model = EnhancedLSTM(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "# функция потерь и оптимизатор\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
        "\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "ey-4j2cNB-cw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение модели"
      ],
      "metadata": {
        "id": "ZLJ_XzJkzKQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50  # Количество эпох при обучении\n",
        "train_hist = []\n",
        "test_hist = []\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    model.train()\n",
        "    for batch_X, batch_y in train_loader:  # выборка разделяется на части (батчи)\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        predictions = model(batch_X)\n",
        "        loss = loss_fn(predictions, batch_y)  # для каждого батча считается функция потерь\n",
        "\n",
        "        # обратное распространение ошибки\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    train_hist.append(average_loss)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_test_loss = 0.0\n",
        "\n",
        "        for batch_X_test, batch_y_test in test_loader:\n",
        "            batch_X_test, batch_y_test = batch_X_test.to(device), batch_y_test.to(device)\n",
        "            predictions_test = model(batch_X_test)\n",
        "            test_loss = loss_fn(predictions_test, batch_y_test)\n",
        "\n",
        "            total_test_loss += test_loss.item()\n",
        "\n",
        "        average_test_loss = total_test_loss / len(test_loader)\n",
        "        test_hist.append(average_test_loss)\n",
        "\n",
        "    print(\n",
        "        f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}, Test Loss: {average_test_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9k1xEMcsCash",
        "outputId": "0033f5cd-43aa-4304-99a5-c2fee6a92e42"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b972fbd22769>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# обратное распространение ошибки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_hist, label=\"Training loss\")\n",
        "plt.plot(test_hist, label=\"Test loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "06KRGRL2Cjvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, './lstm_enhanced.pth')"
      ],
      "metadata": {
        "id": "1dIXuchoCjvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RL-LqHmFNNhD"
      },
      "cell_type": "markdown",
      "source": [
        "# Свёрточные нейронные сети"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-01T16:45:56.100076Z",
          "start_time": "2025-04-01T16:45:56.096805Z"
        },
        "id": "HTpk9bIkNNhD"
      },
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Простейшая одномерная CNN"
      ],
      "metadata": {
        "id": "lKvwc8YrVjXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Параметры модели"
      ],
      "metadata": {
        "id": "Gp-KMOmLzVTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение модели"
      ],
      "metadata": {
        "id": "M-nMx_2OzXCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Улучшенная одномерная CNN"
      ],
      "metadata": {
        "id": "lAU4BuALVnlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Параметры модели"
      ],
      "metadata": {
        "id": "kuD2EQOHzbzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение модели"
      ],
      "metadata": {
        "id": "J3W-pTMozbzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Одномерная CNN на основе encoder и decoder"
      ],
      "metadata": {
        "id": "N1hpcQBfVr9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VApmxMlcVr7d"
      }
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-01T21:24:08.374352Z",
          "start_time": "2025-04-01T21:24:08.366346Z"
        },
        "id": "Qk986kB_NNhP"
      },
      "cell_type": "code",
      "source": [
        "class EncoderDecoder1dCNN(nn.Module):\n",
        "    def __init__(self, input_size=2, hidden_size=256, kernel_size=3, num_cnn_layers=4, dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Расширяющаяся часть (encoder)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(input_size, hidden_size // 4, kernel_size, padding='same'),\n",
        "            nn.BatchNorm1d(hidden_size // 4),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Conv1d(hidden_size // 4, hidden_size // 2, kernel_size, padding='same'),\n",
        "            nn.BatchNorm1d(hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Середина (с остаточными связями)\n",
        "        self.mid_layers = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv1d(hidden_size // 2, hidden_size // 2, kernel_size, padding='same'),\n",
        "                nn.BatchNorm1d(hidden_size // 2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ) for _ in range(num_cnn_layers)\n",
        "        ])\n",
        "\n",
        "        # Сужающаяся часть (decoder)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv1d(hidden_size // 2, hidden_size // 4, kernel_size, padding='same'),\n",
        "            nn.BatchNorm1d(hidden_size // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Conv1d(hidden_size // 4, input_size, kernel_size, padding='same'),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # Encoder\n",
        "        x = self.encoder(x)\n",
        "\n",
        "        # Middle layers with residual connections\n",
        "        for layer in self.mid_layers:\n",
        "            x = x + layer(x)\n",
        "\n",
        "        # Decoder\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x.permute(0, 2, 1)"
      ],
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка обученной модели (опционально)**"
      ],
      "metadata": {
        "id": "uOmARPqPzmud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Параметры модели"
      ],
      "metadata": {
        "id": "IZ33jXnrzfDi"
      }
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-01T21:24:10.216662Z",
          "start_time": "2025-04-01T21:24:10.206464Z"
        },
        "id": "Cpi5OiPvNNhQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "d97397a5-3cdb-4340-a945-81e7b370a612"
      },
      "cell_type": "code",
      "source": [
        "model = EncoderDecoder1dCNN()\n",
        "\n",
        "# функция потерь и оптимизатор\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
        "loss_fn = nn.MSELoss()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c1abfb7e74dd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# функция потерь и оптимизатор\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         )\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ordered_set\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from torch.utils._sympy.functions import (\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mApplication\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mCeilToInt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_sympy/functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/polys/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m ]\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from .polytools import (Poly, PurePoly, poly_from_expr,\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mparallel_poly_from_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение модели"
      ],
      "metadata": {
        "id": "4gup0sxYzfDj"
      }
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-01T23:38:02.868590Z",
          "start_time": "2025-04-01T21:24:12.602792Z"
        },
        "id": "luv3Ki-GNNhQ"
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 100  # Количество эпох при обучении\n",
        "train_hist = []\n",
        "test_hist = []\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    model.train()\n",
        "    for batch_X, batch_y in train_loader:  # выборка разделяется на части (батчи)\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        predictions = model(batch_X)\n",
        "        loss = loss_fn(predictions, batch_y)  # для каждого батча считается функция потерь\n",
        "\n",
        "        # обратное распространение ошибки\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    train_hist.append(average_loss)\n",
        "\n",
        "    # расчёты для тестовых бачтей\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_test_loss = 0.0\n",
        "\n",
        "        for batch_X_test, batch_y_test in test_loader:\n",
        "            batch_X_test, batch_y_test = batch_X_test.to(device), batch_y_test.to(device)\n",
        "            predictions_test = model(batch_X_test)\n",
        "            test_loss = loss_fn(predictions_test, batch_y_test)\n",
        "\n",
        "            total_test_loss += test_loss.item()\n",
        "\n",
        "        average_test_loss = total_test_loss / len(test_loader)\n",
        "        test_hist.append(average_test_loss)\n",
        "\n",
        "    print(\n",
        "        f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}, Test Loss: {average_test_loss:.4f}')\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-01T23:56:11.813351Z",
          "start_time": "2025-04-01T23:56:11.799031Z"
        },
        "id": "Z6xR82JeNNhQ"
      },
      "cell_type": "code",
      "source": [
        "torch.save(model, 'models/CNNs/cnn1d_1.pth')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ансамбли моделей"
      ],
      "metadata": {
        "id": "0mCzSwT0_lNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Стэкинг GAT и LSTM"
      ],
      "metadata": {
        "id": "DqMHhCniXJgz"
      }
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-26T22:28:35.968962Z",
          "start_time": "2025-03-26T22:28:35.963250Z"
        },
        "id": "ryi7Qn3gNNhR"
      },
      "cell_type": "code",
      "source": [
        "class GNN_RNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 graph_data: \"Data\",\n",
        "                 input_size=2,  # широта и долгота\n",
        "                 hidden_size=128,\n",
        "                 gnn_out_features=64,\n",
        "                 num_gnn_layers=2,\n",
        "                 num_lstm_layers=2,\n",
        "                 num_heads=4,\n",
        "                 dropout=0.2):\n",
        "        super(GNN_RNN, self).__init__()\n",
        "\n",
        "        self.graph_data = graph_data\n",
        "        # GNN часть (используем Graph Attention Network)\n",
        "        self.gnn_layers = nn.ModuleList()\n",
        "        self.gnn_layers.append(GATConv(input_size, hidden_size, heads=num_heads, dropout=dropout))\n",
        "        for _ in range(num_gnn_layers - 1):\n",
        "            self.gnn_layers.append(GATConv(hidden_size * num_heads, hidden_size, heads=num_heads, dropout=dropout))\n",
        "\n",
        "        self.gnn_to_lstm = nn.Linear(hidden_size * num_heads, gnn_out_features)\n",
        "\n",
        "        # RNN часть (используем LSTM)\n",
        "        self.lstm = nn.LSTM(input_size=gnn_out_features + input_size,  # объединяем координаты и признаки узлов\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=num_lstm_layers,\n",
        "                            dropout=dropout if num_lstm_layers > 1 else 0,\n",
        "                            bidirectional=False,\n",
        "                            batch_first=True)\n",
        "\n",
        "        # Выходной слой\n",
        "        self.output_layer = nn.Linear(hidden_size, 1)  # предсказываем вероятность для каждого узла\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gnn_out_features = gnn_out_features\n",
        "\n",
        "    def forward(self, route_sequence, node_candidates):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            route_sequence: [batch_size, seq_len, input_size] последовательность координат маршрута\n",
        "            node_candidates: [batch_size, seq_len, max_candidates] кандидаты узлов для каждой точки маршрута\n",
        "        Returns:\n",
        "            [batch_size, seq_len, max_candidates] вероятности для каждого кандидата\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = route_sequence.size()[:2]\n",
        "        max_candidates = node_candidates.size()[2]\n",
        "\n",
        "        # 1. Обрабатываем граф с помощью GNN\n",
        "        x, edge_index = self.graph_data.x, self.graph_data.edge_index\n",
        "        for layer in self.gnn_layers:\n",
        "            x = layer(x, edge_index)\n",
        "            x = F.leaky_relu(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        x = self.gnn_to_lstm(x)  # [num_nodes, gnn_out_features]\n",
        "\n",
        "        # 2. Для каждого шага маршрута собираем признаки кандидатов\n",
        "        # node_candidates: [batch_size, seq_len, max_candidates]\n",
        "        # x: [num_nodes, gnn_out_features] -> расширяем для всех кандидатов\n",
        "        candidate_features = x[node_candidates.view(-1)].view(batch_size, seq_len, max_candidates,\n",
        "                                                              self.gnn_out_features)\n",
        "\n",
        "        # 3. Добавляем координаты маршрута к признакам кандидатов\n",
        "        route_expanded = route_sequence.unsqueeze(2).expand(-1, -1, max_candidates, -1)\n",
        "        lstm_input = torch.cat([candidate_features, route_expanded], dim=-1)\n",
        "\n",
        "        # 4. Обрабатываем последовательность с помощью LSTM\n",
        "        lstm_out, _ = self.lstm(lstm_input.view(-1, seq_len, self.gnn_out_features + 2))\n",
        "        lstm_out = lstm_out.contiguous().view(batch_size, seq_len, max_candidates, self.hidden_size)\n",
        "\n",
        "        # 5. Предсказываем вероятности для каждого кандидата\n",
        "        logits = self.output_layer(lstm_out).squeeze(-1)  # [batch_size, seq_len, max_candidates]\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        return probs\n",
        "\n",
        "    def predict(self, graph_data, route_sequence, node_candidates, k=1):\n",
        "        \"\"\"Предсказание топ-k наиболее вероятных узлов для каждого шага маршрута\"\"\"\n",
        "        probs = self.forward(graph_data, route_sequence, node_candidates)\n",
        "        topk_probs, topk_indices = torch.topk(probs, k=k, dim=2)\n",
        "        return topk_indices, topk_probs"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-26T22:27:29.319217Z",
          "start_time": "2025-03-26T22:27:27.989218Z"
        },
        "id": "OvOQJpPqNNhR"
      },
      "cell_type": "code",
      "source": [
        "# Загрузка графа дорог Воронежа\n",
        "datapath = \"training data\"\n",
        "\n",
        "# Атрибуты вершины: координаты, id, кол-вол улиц\n",
        "nodes = gpd.read_file(os.path.join(datapath, \"nodes.csv\"), encoding=\"utf8\")\n",
        "nodes = nodes.iloc[:, :4]\n",
        "nodes = nodes.astype('float32')\n",
        "\n",
        "edges = gpd.read_file(os.path.join(datapath, \"edges.csv\"), encoding=\"utf8\")\n",
        "edge_index = edges[['u', 'v']]\n",
        "edge_index = edge_index.astype('int64')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-26T22:27:29.781396Z",
          "start_time": "2025-03-26T22:27:29.776511Z"
        },
        "id": "Ee2N303oNNhS"
      },
      "cell_type": "code",
      "source": [
        "nodes_t = torch.tensor(nodes.values)\n",
        "edge_index_t = torch.tensor(edge_index.values)\n",
        "graph = Data(x=nodes_t, edge_index=edge_index_t)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-26T22:29:31.871301Z",
          "start_time": "2025-03-26T22:29:31.866097Z"
        },
        "id": "baVkGb6TNNhS",
        "outputId": "7552894a-0574-4742-c5e7-05f33264a83f"
      },
      "cell_type": "code",
      "source": [
        "print(\"Node features shape:\", graph.x.shape)  # Должно быть [N, 2]\n",
        "print(\"Edge index shape:\", graph.edge_index.shape)  # Должно быть [2, E]"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node features shape: torch.Size([7352, 4])\n",
            "Edge index shape: torch.Size([19200, 2])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-26T22:29:07.330501Z",
          "start_time": "2025-03-26T22:29:07.322256Z"
        },
        "id": "UdX2IaqANNhS"
      },
      "cell_type": "code",
      "source": [
        "# Параметры модели\n",
        "out_channels = 64\n",
        "in_channels = 4\n",
        "output_size = 2\n",
        "batch_size = 128\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# создаём модель\n",
        "model = GNN_RNN(graph).to(device)\n",
        "\n",
        "# оптимизатор\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# в качестве функции потерь - СТС, так как последовательности разнородной длины\n",
        "loss_fn = nn.CTCLoss()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-26T22:28:39.776821Z",
          "start_time": "2025-03-26T22:28:39.740978Z"
        },
        "id": "aqiCEGbtNNhS"
      },
      "cell_type": "code",
      "source": [
        "X, y = data['X'], data['y']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    train_size=0.8,\n",
        "                                                    random_state=42)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-26T22:28:41.803472Z",
          "start_time": "2025-03-26T22:28:40.511285Z"
        },
        "id": "r-vmZ62aNNhS"
      },
      "cell_type": "code",
      "source": [
        "X_train = [torch.tensor(seq, dtype=torch.float32) for seq in X_train]\n",
        "y_train = [torch.tensor(seq, dtype=torch.float32) for seq in y_train]\n",
        "X_train_pad = pad_sequence(X_train, batch_first=True)\n",
        "y_train_pad = pad_sequence(y_train, batch_first=True)\n",
        "\n",
        "X_test = [torch.tensor(seq, dtype=torch.float32) for seq in X_test]\n",
        "y_test = [torch.tensor(seq, dtype=torch.float32) for seq in y_test]\n",
        "X_test_pad = pad_sequence(X_test, batch_first=True)\n",
        "y_test_pad = pad_sequence(y_test, batch_first=True)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_pad, y_train_pad)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataset = TensorDataset(X_test_pad, y_test_pad)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-26T22:29:09.515147Z",
          "start_time": "2025-03-26T22:29:09.293773Z"
        },
        "id": "PLt1QU8PNNhT",
        "outputId": "ab868b6d-abb7-4ded-f0e7-a758dbbbf2c8"
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 50  # Количество эпох при обучении\n",
        "train_hist = []\n",
        "test_hist = []\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    model.train()\n",
        "    for batch_X, batch_y in train_loader:  # выборка разделяется на части (батчи)\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        predictions = model(batch_X)\n",
        "        loss = loss_fn(predictions, batch_y)  # для каждого батча считается функция потерь\n",
        "\n",
        "        # обратное распространение ошибки\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    train_hist.append(average_loss)\n",
        "\n",
        "    # расчёты для тестовых бачтей\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_test_loss = 0.0\n",
        "\n",
        "        for batch_X_test, batch_y_test in test_loader:\n",
        "            batch_X_test, batch_y_test = batch_X_test.to(device), batch_y_test.to(device)\n",
        "            predictions_test = model(batch_X_test)\n",
        "            test_loss = loss_fn(predictions_test, batch_y_test)\n",
        "\n",
        "            total_test_loss += test_loss.item()\n",
        "\n",
        "        average_test_loss = total_test_loss / len(test_loader)\n",
        "        test_hist.append(average_test_loss)\n",
        "\n",
        "    print(\n",
        "        f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}, Test Loss: {average_test_loss:.4f}')\n"
      ],
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Sizes of tensors must match except in dimension 1. Expected size 19200 but got size 2 for tensor number 1 in the list.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_X, batch_y \u001b[38;5;129;01min\u001b[39;00m train_loader:  \u001b[38;5;66;03m# выборка разделяется на части (батчи)\u001b[39;00m\n\u001b[32m      8\u001b[39m     batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     predictions = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     loss = loss_fn(predictions, batch_y)  \u001b[38;5;66;03m# для каждого батча считается функция потерь\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# обратное распространение ошибки\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mGATxRNN.forward\u001b[39m\u001b[34m(self, route_coords)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, route_coords):\n\u001b[32m     35\u001b[39m     route_emb = \u001b[38;5;28mself\u001b[39m.coord_encoder(route_coords)  \u001b[38;5;66;03m# [seq_len, hidden_dim]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     node_emb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [num_nodes, hidden_dim]\u001b[39;00m\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# 3. Сопоставляем точки маршрута с узлами графа через внимание\u001b[39;00m\n\u001b[32m     39\u001b[39m     corrected_emb, _ = \u001b[38;5;28mself\u001b[39m.attention(\n\u001b[32m     40\u001b[39m         route_emb, node_emb, node_emb\n\u001b[32m     41\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:349\u001b[39m, in \u001b[36mGATConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[39m\n\u001b[32m    346\u001b[39m     num_nodes = \u001b[38;5;28mmin\u001b[39m(size) \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_nodes\n\u001b[32m    347\u001b[39m     edge_index, edge_attr = remove_self_loops(\n\u001b[32m    348\u001b[39m         edge_index, edge_attr)\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m     edge_index, edge_attr = \u001b[43madd_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.edge_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch_geometric\\utils\\loop.py:472\u001b[39m, in \u001b[36madd_self_loops\u001b[39m\u001b[34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[39m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    470\u001b[39m     loop_index = torch.arange(\u001b[32m0\u001b[39m, N, device=device).view(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m).repeat(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m full_edge_index = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sparse:\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m edge_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[31mRuntimeError\u001b[39m: Sizes of tensors must match except in dimension 1. Expected size 19200 but got size 2 for tensor number 1 in the list."
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестирование моделей"
      ],
      "metadata": {
        "id": "1IsHsTYAUS2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка файла конфигурации (config.json). Он передаётся классу, который описан ниже."
      ],
      "metadata": {
        "id": "H4qW8lvnzCsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1uTIYTjQHau5R0kOhQG3lspQ-EA16SHxp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRIJEdPpwEDS",
        "outputId": "b220dd07-e1b2-4636-a042-31e609d4a904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uTIYTjQHau5R0kOhQG3lspQ-EA16SHxp\n",
            "To: /content/config.json\n",
            "\r  0% 0.00/163 [00:00<?, ?B/s]\r100% 163/163 [00:00<00:00, 397kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Класс генератора маршрутов"
      ],
      "metadata": {
        "id": "neI78t0Y1Fs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данный класс использовался для генерации 10.000 пар маршрутов для выборки. С помощью него также можно получить граф дорог, который получается с помощью заключения выбранной области в прямоугольник. Для этого выбирается верхняя левая и нижняя правая точки."
      ],
      "metadata": {
        "id": "3sKb8V3WUlkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RouteGenerator:\n",
        "    def __init__(self, config_path: str = \"config.json\", **kwargs):\n",
        "        \"\"\"Конструктор класса, которому в именованных аргументах передаётся\n",
        "        либо название местности, либо точные координаты местности.\n",
        "        Если было передано название, то происходит обращение к базе данных OSM,\n",
        "        где потом извлекаются точные координаты. На основе координат строится граф дорог.\n",
        "\n",
        "\n",
        "        Args:\n",
        "            config_path (str, optional): Путь к файлу конфигурации. По умолчанию стоит \"config.json\".\n",
        "\n",
        "        Raises:\n",
        "            Exception: Не были переданы ни название местности, ни его координаты.\n",
        "        \"\"\"\n",
        "\n",
        "        self.__load_config(config_path)\n",
        "        self.data = {'X': [], 'y': []}\n",
        "\n",
        "        if \"place_name\" in kwargs.keys():\n",
        "            self.__place_bbox = list(\n",
        "                ox.geocode_to_gdf(kwargs[\"place_name\"]).geometry.total_bounds\n",
        "            )\n",
        "\n",
        "        elif \"place_bbox\" in kwargs.keys():\n",
        "            self.__place_bbox = kwargs[\"place_bbox\"]\n",
        "        else:\n",
        "            raise Exception(\n",
        "                \"Укажите название места согласно базе данных OSM либо координаты местности.\"\n",
        "            )\n",
        "\n",
        "        self.graph = ox.graph_from_bbox(self.__place_bbox, network_type=\"drive\")  # Граф дорог местности\n",
        "\n",
        "    def __load_config(self, file_path: str) -> None:\n",
        "        \"\"\"Загрузка данных о константах через файл конфигурации.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Путь к файлу конфигурации.\n",
        "        \"\"\"\n",
        "\n",
        "        with open(file_path, \"r\") as file:\n",
        "            config = json.load(file)\n",
        "            self.__data_amount = config[\"data_amount\"]  # Размер генерируемой выборки\n",
        "            self.__min_segment = config[\n",
        "                \"min_segment\"\n",
        "            ]  # Минимальное значение отрезка для создания отклонения\n",
        "            self.__max_segment = config[\n",
        "                \"max_segment\"\n",
        "            ]  # Максимальное значение отрезка для создания отклонения\n",
        "            self.__min_offset = config[\"min_offset\"]  # Минимальное отклонение\n",
        "            self.__max_offset = config[\"max_offset\"]  # Максимальное отклонение\n",
        "            self.__max_route_len = config[\"max_route_len\"]\n",
        "            self.__min_route_len = config[\"min_route_len\"]\n",
        "\n",
        "    def save_false_route(self, main_route: list) -> tuple:\n",
        "        \"\"\"Генерация одного искажённого маршрута на основе исходного.\n",
        "\n",
        "        Args:\n",
        "            main_route: (list): Исходный маршрут.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[nx.Graph, list]: Кортеж, внутри которого помещён изменённый граф и полученный маршрут.\n",
        "        \"\"\"\n",
        "\n",
        "        path = main_route\n",
        "        G = self.graph.copy()\n",
        "        new_nodes = [path[0]]\n",
        "\n",
        "        for i in range(len(path) - 1):\n",
        "            # Начальная и конечная точки отрезка\n",
        "            u, v = path[i], path[i + 1]\n",
        "            point1 = (G.nodes[u][\"y\"], G.nodes[u][\"x\"])\n",
        "            point2 = (G.nodes[v][\"y\"], G.nodes[v][\"x\"])\n",
        "\n",
        "            # Расстояние между узлами\n",
        "            edge_length = gd(point1, point2).meters\n",
        "            direction_bearing = ox.bearing.calculate_bearing(\n",
        "                point1[0], point1[1], point2[0], point2[1]\n",
        "            )\n",
        "\n",
        "            # Добавление точек через случайное расстояние между 20 и 60 метров\n",
        "            current_dist = 0\n",
        "            previous_node = u\n",
        "            while current_dist < edge_length:\n",
        "                # Случайное расстояние до следующей точки\n",
        "                random_dist = random.uniform(self.__min_segment, self.__max_segment)\n",
        "                current_dist += random_dist\n",
        "\n",
        "                if current_dist >= edge_length:\n",
        "                    break\n",
        "\n",
        "                # Вычисление промежуточной точки\n",
        "                new_point = gd(meters=current_dist).destination(\n",
        "                    point1, direction_bearing\n",
        "                )\n",
        "                new_lat, new_lon = new_point.latitude, new_point.longitude\n",
        "\n",
        "                # Случайное отклонение влево или вправо\n",
        "                offset_direction = direction_bearing + (\n",
        "                    90 if random.choice([True, False]) else -90\n",
        "                )\n",
        "                offset_dist = random.uniform(self.__min_offset, self.__max_offset)\n",
        "                offset_point = gd(meters=offset_dist).destination(\n",
        "                    (new_lat, new_lon), offset_direction\n",
        "                )\n",
        "                offset_lat, offset_lon = (offset_point.latitude, offset_point.longitude)\n",
        "\n",
        "                # Добавление новой вершины и её координат\n",
        "                new_node = max(G.nodes) + 1\n",
        "                G.add_node(new_node, y=offset_lat, x=offset_lon)\n",
        "                new_nodes.append(new_node)\n",
        "\n",
        "                # Добавление ребра между новой точкой и предыдущей точкой\n",
        "                G.add_edge(previous_node, new_node, length=random_dist)\n",
        "                G.add_edge(\n",
        "                    new_node, v, length=edge_length - current_dist\n",
        "                )  # Связь с основным маршрутом\n",
        "\n",
        "                previous_node = new_node  # Сместить начальную точку для следующего шага\n",
        "            new_nodes.append(path[i + 1])\n",
        "\n",
        "        false_route = [(G.nodes[n][\"x\"], G.nodes[n][\"y\"]) for n in new_nodes]\n",
        "        return G, false_route\n",
        "\n",
        "    def save_main_route(self) -> tuple:\n",
        "        \"\"\"Генерация и сохранение исходного маршрута\n",
        "\n",
        "        Args: _\n",
        "        \"\"\"\n",
        "        keys = list(self.graph.nodes.keys()).copy()\n",
        "        node_ids = []\n",
        "\n",
        "        while len(node_ids) < self.__min_route_len or len(node_ids) > self.__max_route_len:\n",
        "            try:\n",
        "                start = random.choice(keys)\n",
        "                keys.remove(start)\n",
        "                end = random.choice(keys)\n",
        "                # Поиск кратчайшего пути\n",
        "                node_ids = nx.astar_path(self.graph, start, end, weight=\"length\")\n",
        "            except nx.NetworkXNoPath:\n",
        "                pass\n",
        "        main_route = [(self.graph.nodes[n][\"x\"], self.graph.nodes[n][\"y\"])\n",
        "                      for n in node_ids]\n",
        "        return node_ids, main_route\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_cumulative_distances(route: \"np.ndarray\"):\n",
        "        distances = [0]  # Начинаем с 0 элемента\n",
        "        for i in range(1, len(route)):\n",
        "            lon1, lat1 = route[i - 1]\n",
        "            lon2, lat2 = route[i]\n",
        "            distance = haversine((lon1, lat1), (lon2, lat2), unit=Unit.METERS)\n",
        "            distances.append(distances[-1] + distance)\n",
        "        return np.array(distances)\n",
        "\n",
        "    # Функция для интерполяции маршрута\n",
        "\n",
        "    def make_equal(self, route: list, num_points: int) -> list:\n",
        "        route = np.array(route)\n",
        "        # Вычисляем кумулятивное расстояние\n",
        "        distances = self.calculate_cumulative_distances(route)\n",
        "\n",
        "        # Создаем интерполяционные функции для широты и долготы\n",
        "        interpolation_func_lon = interp1d(distances, route[:, 0], kind='linear')\n",
        "        interpolation_func_lat = interp1d(distances, route[:, 1], kind='linear')\n",
        "\n",
        "        new_distances = np.linspace(0, distances[-1], num_points)\n",
        "\n",
        "        new_lon = interpolation_func_lon(new_distances)\n",
        "        new_lat = interpolation_func_lat(new_distances)\n",
        "        new_route = list(np.column_stack((new_lon, new_lat)))\n",
        "        new_route = [tuple(point) for point in new_route]\n",
        "        return new_route\n",
        "\n",
        "    def save_data(self) -> None:\n",
        "        for i in range(self.__data_amount):\n",
        "            route_ids, main_route = self.save_main_route()\n",
        "            _, false_route = self.save_false_route(route_ids)\n",
        "\n",
        "            main_route = self.make_equal(main_route, len(false_route))\n",
        "            self.data['y'].append(main_route)\n",
        "            self.data['X'].append(false_route)\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f\"Сделано {i + 1}/{self.__data_amount} маршрутов\")\n"
      ],
      "metadata": {
        "id": "6h9wt_KDgiAI",
        "ExecuteTime": {
          "end_time": "2025-04-01T20:40:59.628499Z",
          "start_time": "2025-04-01T20:40:59.602569Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функции для запуска примера"
      ],
      "metadata": {
        "id": "u73_9yRs1KUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве примера будут созданы 3 html-файла в папке example:\n",
        "- *input* - входной маршрут\n",
        "- *target* - целевой маршрут\n",
        "- *predict* - предсказанный моделью маршрут"
      ],
      "metadata": {
        "id": "SOrS10Ci4b3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_route(points: list, save_folder: str, name: str) -> None:\n",
        "    # Создаем карту, центрированную на первой точке\n",
        "    points = [(point[1], point[0]) for point in points]\n",
        "    plot = folium.Map(location=points[0], zoom_start=15)\n",
        "\n",
        "    # Соединяем точки линией (маршрут)\n",
        "    folium.PolyLine(points, color=\"red\", weight=2, opacity=1).add_to(plot)\n",
        "\n",
        "    # Сохраняем карту в HTML-файл и открываем его\n",
        "    plot.save(f\"{save_folder}/{name}.html\")\n",
        "\n",
        "\n",
        "def model_test(save_folder: str, trained_model: \"nn.Module\") -> None:\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    test_model = trained_model\n",
        "    test_model.eval()\n",
        "\n",
        "    sc = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "    place_bbox = [39.0296, 51.7806, 39.3414, 51.5301]\n",
        "\n",
        "    generator = RouteGenerator(place_bbox=place_bbox, config_path=\"configs\\\\config.json\")\n",
        "    G, result = generator.graph, generator.save_main_route()\n",
        "    main_ids, main_coords = result\n",
        "    G_false, false_coords = generator.save_false_route(main_ids)\n",
        "\n",
        "    main_coords = generator.make_equal(main_coords, len(false_coords))\n",
        "\n",
        "    save_route(main_coords, save_folder, \"target\")\n",
        "    save_route(false_coords, save_folder, \"input\")\n",
        "\n",
        "    false_coords = torch.tensor(sc.fit_transform(false_coords), dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        predict = test_model(false_coords)\n",
        "    predict = sc.inverse_transform(predict.detach().numpy())\n",
        "    print(predict)\n",
        "    save_route(predict, save_folder, \"predict\")\n",
        "    print(f\"MSE: {mean_squared_error(predict, main_coords)} \\t MAE: {mean_absolute_error(predict, main_coords)}\")\n"
      ],
      "metadata": {
        "id": "1KgyHYtKgVDI",
        "ExecuteTime": {
          "end_time": "2025-04-01T20:42:26.699063Z",
          "start_time": "2025-04-01T20:42:26.690794Z"
        }
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тестирование RNN"
      ],
      "metadata": {
        "id": "q4jUyVBLW1Ep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тестирование 1dCNN"
      ],
      "metadata": {
        "id": "7KjjSJnuW34i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тестирование ансамблей"
      ],
      "metadata": {
        "id": "ljRCd37_W6zO"
      }
    }
  ]
}